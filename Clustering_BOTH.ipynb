{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GotAMinor/Training/blob/main/Clustering_BOTH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l96XD2NrEUip"
      },
      "source": [
        "<!-- JPN -->\n",
        "# クラスタリング\n",
        "\n",
        "※本演習資料の二次配布・再配布はお断り致します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZleCt3elD_KP"
      },
      "source": [
        "<!-- ENG -->\n",
        "# Clustering\n",
        "\n",
        "※Distribution or redistribution of these exercise materials without the copyright holder's permission is not permitted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ7m2grsrj6Z"
      },
      "source": [
        "<!-- JPN -->\n",
        "　今回の演習の内容は以下の通りである。\n",
        "\n",
        "- **1 | データセットの準備**\n",
        "- **2 | 階層的クラスタリング (Hierarchical clustering)**\n",
        "- **3 | <var>K</var>-meansクラスタリング (<var>K</var>-means clustering)**\n",
        "- **4 | クラスタリングを用いた仮説提案の例**\n",
        "\n",
        "　クラスタリングには多数のアルゴリズムがあるが、今回は比較的理解しやすい階層的クラスタリングと<var>K</var>-meansクラスタリングを扱う。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvs7c8NGD_KR"
      },
      "source": [
        "<!-- ENG -->\n",
        "　The practice exercises this time are the following.\n",
        "\n",
        "- **1 | Preparing a data set**\n",
        "- **2 | Hierarchical clustering**\n",
        "- **3 | <var>K</var>-means clustering**\n",
        "- **4 | Example of a hypothesis formulation using clustering**\n",
        "\n",
        "　There are many algorithms for clustering, but this time we will deal with hierarchical clustering and <var>K</var>-means clustering, which are relatively easy to understand.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruol05eWK47C"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gljJItdRLt9H"
      },
      "source": [
        "<!-- JPN -->\n",
        "## 1 | データセットの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_gYw_NID_KS"
      },
      "source": [
        "<!-- ENG -->\n",
        "## 1 | Preparing a data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5jNlgyVNuVU"
      },
      "source": [
        "<!-- JPN -->\n",
        "　今回は性質の異なる二つのデータセットを取り扱う。一つはGaussianデータセットで、中心と分散の異なる正規分布からそれぞれのクラスタが生成される。もう一つはmoonデータセットで、それぞれのクラスタが三日月型をしており、それらを組み合わせた形状をしている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LknczRcAD_KX"
      },
      "source": [
        "<!-- ENG -->\n",
        "　This time, we will use two data sets that have different properties. One is the Gaussian data set, where each cluster is generated from a normal distribution with different centers and variances. The other is the moon data set, where each cluster has a crescent moon shape, and the shape is a combination of those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-OuLHHWpssL"
      },
      "source": [
        "<!-- JPN -->\n",
        "　下のセルがGaussianデータセットを生成する関数である。`centers`に正規分布の中心のリスト、`stds`に標準偏差のリスト、`sizes`にデータ数のリストをとる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls4bVspaD_KZ"
      },
      "source": [
        "<!-- ENG -->\n",
        "　The bottom cell is the function that generates the Gaussian data set. The function takes the following arguments: a list of normal distribution centers for `centers`, a list of standard deviations for `stds`, and a list of number of data sets for `sizes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIGknYHNCamq"
      },
      "outputs": [],
      "source": [
        "# dataset generation\n",
        "import numpy as np\n",
        "from numpy.random import normal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gen_2d_gaussian(centers, stds, sizes, random_state=0):\n",
        "  # generate data based on 2D-gaussian\n",
        "  np.random.seed(random_state)\n",
        "\n",
        "  clusters = []\n",
        "  labels = []\n",
        "  # for each cluster\n",
        "  for i in range(len(sizes)):\n",
        "    clusters.append(normal(centers[i], stds[i], size=(sizes[i], 2)))\n",
        "    labels.extend([i]*sizes[i])\n",
        "  ret = np.concatenate(clusters, axis=0) \n",
        "  return ret, np.array(labels)\n",
        "  \n",
        "# default parameter: gen_2d_gaussian([(0, 0), (5, 0)], [0.75, 1.25], [100, 300])\n",
        "data_gaussian, labels_gaussian = gen_2d_gaussian([(0, 0), (5, 0)], [0.75, 1.25], [100, 300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq8DQ93qOL-i"
      },
      "source": [
        "<!-- JPN -->\n",
        "　moonデータセットはscikit-learnに用意されている関数を用いて生成する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKZyEFdoD_Ka"
      },
      "source": [
        "<!-- ENG -->\n",
        "　The moon data set is generated using a function provided in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ZVYddJMDH-"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "data_moon, labels_moon = make_moons(n_samples=300, noise=0.05, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZBoZ6-PJYSP"
      },
      "source": [
        "<!-- JPN -->\n",
        "　作成したデータセットを見てみよう。`plot_clustering`はクラスタリングした結果をプロットする関数である。`cluster_labels`が各データがどのクラスタに属しているかの情報で、これを基にデータの色を決定している。\n",
        "\n",
        "　ここではデータセットを生成した際のクラスタ番号（真のラベル）を用いている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da9_kV2TD_Kb"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Let's take a look at the data set that was created. `plot_clustering` is a function to plot the result of clustering. The `cluster_labels` is the information about which cluster each data belongs to, and the color of the data is determined based on this information.\n",
        "\n",
        "　Here, we use the cluster number (true label) when the data set was generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNSx_CqSKuqW",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# function for plot cluster by color\n",
        "def plot_clustering(data, cluster_labels, n_clusters=2, title=None, multi_color=True):\n",
        "\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  cmap = plt.get_cmap('gist_rainbow')\n",
        "  for i in range(n_clusters):\n",
        "    if multi_color:\n",
        "      color_float = i/n_clusters\n",
        "    else:\n",
        "      color_float = 0\n",
        "    plt.scatter(data[cluster_labels==i, 0], data[cluster_labels==i, 1],\n",
        "                color=cmap(color_float))\n",
        "    \n",
        "\n",
        "  plt.axis('equal') # make figure square (1:1 aspect ratio)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7zf4yQcWIL_"
      },
      "outputs": [],
      "source": [
        "plot_clustering(data_gaussian, labels_gaussian, title=\"Gaussian dataset (true label)\", multi_color=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNz4xgGBSLLg"
      },
      "outputs": [],
      "source": [
        "plot_clustering(data_moon, labels_moon, title=\"moon dataset (true label)\", multi_color=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoAhhhGWUSOc"
      },
      "source": [
        "<!-- JPN -->\n",
        "　なお、今回はデータがどのクラスタに属しているかを事前に知っているが、実際のデータセットではデータがどのクラスタに属しているかが未知（教師なし）であることに注意せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPYtOYJsD_Kc"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Note that in this case, we know in advance which cluster the data belongs to, but in the actual data set, it is unknown (unsupervised) which cluster the data belongs to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae1cz31uLG01"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_jpkJu7PPe"
      },
      "source": [
        "<!-- JPN -->\n",
        "## 2 | 階層的クラスタリング (Hierarchical clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDys32BvD_Kd"
      },
      "source": [
        "<!-- ENG -->\n",
        "## 2 | Hierarchical clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skfio_r71bXV"
      },
      "source": [
        "<!-- JPN -->\n",
        "　クラスタリングとは、データをその特徴だけを用いて複数のグループ（クラスタ）に分割する手法のことである。同一クラスタに属するデータは互いに類似しており、異なるクラスタに属するデータは互いに類似していないことが望ましい。\n",
        "\n",
        "　階層的クラスタリングには2種類の手法があり、**トップダウン（分割型; divisive hierarchical clustering）**と**ボトムアップ（凝集型; agglomerative hierarchical clustering）**である。\n",
        "トップダウン手法では、決定木のように、すべてのデータが含まれる一つのクラスタを初期状態とし、最もよくデータを分割できる分割でクラスタを二つに分けることを繰り返してクラスタリングを行う。\n",
        "ボトムアップ手法では、すべてのデータが互いに異なるクラスタに属する状態を初期状態とし、クラスタ同士の距離が最も近いペアを一つにまとめる処理を繰り返してクラスタリングを行う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UqdSuliD_Kd"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Clustering is a method of dividing data into multiple groups (clusters) using only its features. Data belonging to the same cluster should be similar to each other, and data belonging to different clusters should not be similar to each other.\n",
        "\n",
        "\n",
        "\n",
        "　There are two types of hierarchical clustering methods: **top-down (divisive hierarchical clustering)** and **bottom-up (agglomerative hierarchical clustering)**.\n",
        "\n",
        "In the top-down method, the initial state is that the cluster contains all data as in a decision tree, and clustering is performed by repeatedly dividing the cluster into two clusters by the split that best divides the data.\n",
        "\n",
        "In the bottom-up method, the initial state is that all data belong to different clusters from each other, and clustering is performed by repeating the process of combining the pairs with the closest distance between clusters into one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUcDhUI81Y2j"
      },
      "source": [
        "<!-- JPN -->\n",
        "　このうち、単純な実装において計算コストの面で優れているのはボトムアップ法である。直感的な理由としては、データ数を $N$ としたときトップダウン法の最初の分割の仕方はおよそ $2^N$ 通りあるのに対し、ボトムアップ法での最初のクラスタのまとめ方はおよそ $N^2$ 通りだからである。ここでは、ボトムアップ法について、実際にコードを実行してみる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzlbRxjHD_Ke"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Of these, the bottom-up method is superior in terms of computational cost for simple implementations. The intuitive reason is that when the number of data is $N$, there are approximately $2^N$ ways to divide the first cluster using the top-down method, while there are approximately $N^2$ ways to group the first cluster using the bottom-up method. Here, we will try to run the actual code using the bottom-up method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO5Jz75gL4jU"
      },
      "source": [
        "<!-- JPN -->\n",
        "　次のセルが実際にクラスタリングを行う部分である。クラスタ間の類似度を判定する方法が`linkage`で定義されている。`linkage`は\n",
        "\n",
        "　`\"ward\", \"complete\", \"average\", \"single\"`\n",
        "\n",
        "から選ぶことができる。これらの手法の詳細は講義の資料を参照せよ。なお、scikit-learnのデフォルトでは一般的によく用いられるWard法 (`\"ward\"`) が用いられている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVT6VG56D_Ke"
      },
      "source": [
        "<!-- ENG -->\n",
        "　The next cell is the part where the actual clustering is performed. A method to determine the similarity between clusters is defined in `linkage`. The choices for `linkage`are:\n",
        "\n",
        "　`\"ward\", \"complete\", \"average\", \"single\"`\n",
        "\n",
        "  Refer to the lecture materials for details of these methods. By default, scikit-learn uses the commonly used Ward's method (`\"ward\"`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryaHtUOq_4QK"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from collections import Counter\n",
        "\n",
        "n_clusters = 2\n",
        "method = \"ward\" # CHANGE HERE\n",
        "\n",
        "# do clustering\n",
        "clustering = AgglomerativeClustering(linkage=method, n_clusters=n_clusters)\n",
        "clustering.fit(data_gaussian)\n",
        "\n",
        "# print number of cluster members\n",
        "member_0 = np.count_nonzero(clustering.labels_==0)\n",
        "member_1 = np.count_nonzero(clustering.labels_==1)\n",
        "print(f\"Number of cluster members: ({member_0}, {member_1})\")\n",
        "\n",
        "plot_clustering(data_gaussian, clustering.labels_, \n",
        "                n_clusters=n_clusters, title=f\"{method}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw2as7HOFPhO"
      },
      "source": [
        "<!-- JPN -->\n",
        "　階層的クラスタリングの場合、**どのようにボトムアップでクラスタが形成されたか**を**樹形図 (dendrogram)** で確認することができる。\n",
        "\n",
        "　樹形図を描画したい場合、 `sklearn.cluster.AgglomerativeClustering()` を用いるより、 SciPy という別のライブラリを用いた方が良いので、こちらを利用する。（**補足資料 ※1**）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN48gJ_ID_Kf"
      },
      "source": [
        "<!-- ENG -->\n",
        "　In the case of hierarchical clustering, a **dendrogram** can be used **to check how the clusters were formed using the bottom-up method**.\n",
        "\n",
        "　If you want to draw a dendrogram, it is better to use another library called SciPy rather than `sklearn.cluster.AgglomerativeClustering()`, so use this one. (**Supplementary Material S1**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmk9I1tnFul2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster import hierarchy\n",
        "\n",
        "Z = hierarchy.linkage(data_gaussian, method=method)\n",
        "hierarchy.dendrogram(Z, color_threshold=0)\n",
        "plt.ylabel(\"distance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhTkb_T3Kx-I"
      },
      "source": [
        "<!-- JPN -->\n",
        "　階層的クラスタリングによって、「2つのクラスタに分ける」とは、**樹形図を2つの（より小さな）樹形図になるように横向きに**（＝あるdistanceの閾値を決めて）**はさみを入れることと同値**である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dINElBzMD_Kf"
      },
      "source": [
        "<!-- ENG -->\n",
        "　With hierarchical clustering, \"dividing into two clusters\" is **equivalent to scissoring a dendrogram horizontally** (i.e., by determining a particular distance threshold) **so that it becomes two (smaller) dendrograms**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkGt8t5-LXY7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrR1GBnWIOoA"
      },
      "source": [
        "<!-- JPN -->\n",
        "##### 課題 1\n",
        "　Gaussianデータセット、moonデータセットそれぞれについて、クラスタ間の類似度を判定する手法`linkage`を変化させて実行し、それぞれについてデータをうまくクラスタリングできている手法とできていない手法を1つずつ選べ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LQEcCe2D_Kg"
      },
      "source": [
        "<!-- ENG -->\n",
        "##### Exercise 1\n",
        "For the Gaussian and moon data sets, vary `linkage`, the method for determining the similarity between clusters, execute, and select one method that successfully clusters the data and one method that does not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bskC8Fa9LZpn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_vxlfqLSqN"
      },
      "source": [
        "<!-- JPN -->\n",
        "##### 課題 2\n",
        "\n",
        "課題 1 の結果が起きる理由について考察せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF-JaDC6D_Kg"
      },
      "source": [
        "<!-- ENG -->\n",
        "##### Exercise 2\n",
        "\n",
        "Discuss the reasons why the one is successful and the other is not, as observed in Exercise 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LhBIASHLb6Q"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PVZWvBxOJim"
      },
      "source": [
        "<!-- JPN -->\n",
        "## 3 | <var>K</var>-meansクラスタリング (<var>K</var>-means clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7Hajz_D_Kg"
      },
      "source": [
        "<!-- ENG -->\n",
        "## 3 | <var>K</var>-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfwjrhykOOPP"
      },
      "source": [
        "<!-- JPN -->\n",
        "　**<var>K</var>-meansクラスタリング** は、以下のようなアルゴリズムでクラスタを決定する手法である。\n",
        "\n",
        "1. ランダムに **$k$** 個のクラスタの中心となる点を選ぶ。\n",
        "2. 各データを中心が最も近いクラスタに属させる。\n",
        "3. クラスタの中心を、そのクラスタに属するデータの平均 (**mean**) に更新する。\n",
        "4. 2〜3を収束するまで繰り返す。\n",
        "\n",
        "　<var>K</var>-meansクラスタリングは、\n",
        " * 初期状態をランダムに選び、初期値に依存して結果が変化する\n",
        " * 最終的に、各データはクラスタの中心にもっとも近いクラスタに属する\n",
        " \n",
        "といった性質をもち、クラスタ間の境界は直線もしくは（超）平面となる。\n",
        " \n",
        "　実際に<var>K</var>-meansクラスタリングを行ってみよう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uSmXWp9D_Kh"
      },
      "source": [
        "<!-- ENG -->\n",
        "　**<var>K</var>-means clustering** is a method that uses the following algorithm to determine clusters.\n",
        "\n",
        "1. Randomly choose **$k$** points as the cluster centers.\n",
        "2. Make each data item belong to the cluster whose center is closest to it.\n",
        "3. Update the center of the cluster with the **mean** of the data belonging to that cluster.\n",
        "4. Repeat steps 2 to 3 until convergence.\n",
        "\n",
        "　<var>K</var>-means clustering has the following properties:\n",
        " * Randomly choose the initial state, and the result changes depending on the initial value\n",
        " * In the end, each data belongs to the cluster closest to the cluster center.\n",
        " \n",
        "The boundaries between clusters are straight lines or (hyper)planes.\n",
        " \n",
        "　Let's actually try <var>K</var>-means clustering in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXZiXF8IPFuW"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(random_state=0, n_clusters=2)\n",
        "kmeans.fit(data_gaussian)\n",
        "\n",
        "# print number of cluster members\n",
        "member_0 = np.count_nonzero(kmeans.labels_==0)\n",
        "member_1 = np.count_nonzero(kmeans.labels_==1)\n",
        "print(f\"Number of cluster members: ({member_0}, {member_1})\")\n",
        "\n",
        "plot_clustering(data_gaussian, kmeans.labels_, n_clusters=2, title=\"kmeans\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZGAg7h7ju4A"
      },
      "source": [
        "<!-- JPN -->\n",
        "　次に、`KMeans`ライブラリを用いずに1ステップずつ<var>K</var>-meansクラスタリングを実行し、実際にどのようにクラスタリングが行われるか見てみよう。ここで★はそれぞれの重心を表しており、直線がクラスタ境界を表している。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYrQZCBiD_Kh"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Next, let's run <var>K</var>-means clustering one step at a time without using the `KMeans` library and see how the clustering is actually performed. Here, ★ represents the center of each, and the straight line represents the cluster boundary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE3tqr9E0qY1"
      },
      "outputs": [],
      "source": [
        "def means_of_clusters(data, labels, n_clusters=2):\n",
        "  # return means of clusters\n",
        "  ret = []\n",
        "  for i in range(n_clusters):\n",
        "    ret.append(np.mean(data[labels==i], axis=0))\n",
        "  return np.array(ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-WZ4Fzo2xre"
      },
      "outputs": [],
      "source": [
        "def belong_cluster(data, means):\n",
        "  # return nearest cluster label for each data point\n",
        "  labels = []\n",
        "\n",
        "  # iterate by row (each data)\n",
        "  for data_point in data:\n",
        "    dists = []\n",
        "    # iterate by row (each cluster)\n",
        "    for cluster_center in means:\n",
        "      dist = np.linalg.norm(data_point-cluster_center)\n",
        "      dists.append(dist)\n",
        "\n",
        "    nearest_cluster = np.argmin(dists)\n",
        "    labels.append(nearest_cluster)\n",
        "  return np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMxylDcU4CTO"
      },
      "outputs": [],
      "source": [
        "def plot_kmeans(data, means, cluster_labels, ax, title=None):\n",
        "  # plot K-means clustering \n",
        "  # only for 2 classes, because of cluster boundary implementation\n",
        "  colors = [\"blue\", \"red\"]\n",
        "  n_clusters = 2\n",
        "  for i in range(n_clusters):\n",
        "    # plot each cluster's data points\n",
        "    ax.scatter(data[cluster_labels==i, 0], data[cluster_labels==i, 1],\n",
        "                color=colors[i], s=16, alpha=0.7)\n",
        "    # plot each cluster's mean\n",
        "    ax.scatter([means[i, 0]], [means[i, 1]], marker=\"*\",\n",
        "                color=\"k\", s=92)\n",
        "\n",
        "  # plot cluster boundary (vertical bisector of cluster means)\n",
        "  center = np.mean(means, axis=0)\n",
        "  diff = means[1]-means[0]\n",
        "  ortho_grad = np.array([-diff[1], diff[0]]) / np.linalg.norm(diff) \n",
        "  ax.plot([center[0]-ortho_grad[0]*4, center[0]+ortho_grad[0]*4],\n",
        "          [center[1]-ortho_grad[1]*4, center[1]+ortho_grad[1]*4])\n",
        "  \n",
        "  # set graph appearance\n",
        "  plt.tight_layout()\n",
        "  ax.set_xlim([-3, 9])\n",
        "  ax.set_ylim([-6, 6])\n",
        "  ax.axis('equal')\n",
        "  if title is not None:\n",
        "    plt.title(title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOJPE_crx9jL"
      },
      "outputs": [],
      "source": [
        "# clustering parameter\n",
        "n_clusters = 2\n",
        "initial_range = 5\n",
        "n_iter = 6\n",
        "\n",
        "fig = plt.figure(figsize=(4*n_iter, 4))\n",
        "\n",
        "kmeans_random_seed = 2 # kmeans random seed\n",
        "\n",
        "# randomly choose initial cluster means\n",
        "np.random.seed(kmeans_random_seed)\n",
        "means = np.random.rand(n_clusters, 2)*initial_range\n",
        "\n",
        "for i in range(n_iter):\n",
        "  # belong datapoints to new cluster\n",
        "  kmeans_labels = belong_cluster(data_gaussian, means)\n",
        "\n",
        "  # Add i-th figure (1-origin)\n",
        "  ax = fig.add_subplot(1, n_iter, i+1)\n",
        "  # Pass the figure to plot function\n",
        "  plot_kmeans(data_gaussian, means, kmeans_labels, ax,\n",
        "              title=f\"Step {i}\")\n",
        "\n",
        "  # calculate new means\n",
        "  means = means_of_clusters(data_gaussian, kmeans_labels, n_clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-V7NbczLk4O"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEp2v1tAPh7v"
      },
      "source": [
        "<!-- JPN -->\n",
        "##### 課題 3\n",
        "　先に述べたように、<var>K</var>-meansクラスタリングは、ランダムに選んだ初期状態に依存して結果が変化する。\n",
        "\n",
        "　初期値 (`kmeans_random_seed`) を変化させながら、**自作の**<var>K</var>-meansクラスタリングを実行することで、結果がどのようになるか図を示しながら考察せよ。\n",
        "例えば、どのような領域がランダムな要素に影響されやすく、どのような領域はされにくいだろうか。解答には1つ以上の図を添付すること。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuSz3l7ZD_Kn"
      },
      "source": [
        "<!-- ENG -->\n",
        "##### Exercise 3\n",
        "　As mentioned earlier, the results of <var>K</var>-means clustering changes depending on the randomly chosen initial state.\n",
        "\n",
        "　Execute **your** <var>K</var>-means clustering by changing the initial value (`kmeans_random_seed`) and discuss the results with a diagram.\n",
        "For example, what areas are more likely to be affected by random elements, and what areas are less likely to be? Attach at least one figure to your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_jtr9fOLnE6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHEyFdSQrvg6"
      },
      "source": [
        "<!-- JPN -->\n",
        "##### 課題 4\n",
        "\n",
        "　三日月型データ (moon) を<var>K</var>-meansクラスタリング（クラスタ数は2とする）でクラスタリングするとどうなるだろうか。\n",
        " * **実行前に結果を予想し**、いくつかの初期値 (`kmeans_random_seed`) について自作<var>K</var>-meansクラスタリングを実行した結果と比較して考察せよ。また、\n",
        " * なぜそのような結果になるのかを記述せよ。\n",
        "\n",
        "　なお、ここではデータのスケールを揃えるため三日月型データセットを以下のようにすると良い。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCTbCsquD_Ko"
      },
      "source": [
        "<!-- ENG -->\n",
        "##### Exercise 4\n",
        "\n",
        "　What happens if we cluster the moon data with <var>K</var>-means clustering (the number of clusters is 2)?\n",
        " * **Predict the results prior to execution**, then compare and discuss the results with the actual execution results with your <var>K</var>-means clustering for some initial value (`kmeans_random_seed`), and;  \n",
        " * Describe why that happened\n",
        "\n",
        "　In order to keep the scale of the data the same, the moon data set should be as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG1d_vzR1p_Y"
      },
      "source": [
        "```python\n",
        "kmeans_data_moon = data_moon * 3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0NMKf2GLqYJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECtdTtSkQCtX"
      },
      "source": [
        "<!-- JPN -->\n",
        "##### 課題 5\n",
        "　<var>K</var>-meansクラスタリングはクラスタ数を事前に入力する必要がある。<var>K</var>-meansクラスタリングに限らず、クラスタリングではいくつのクラスタに分けるかを人間が決定しなければならない場合が多く存在する。\n",
        "**クラスタ数を客観的に決めるための方法について、考えて述べよ**。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-J27xCPD_Kp"
      },
      "source": [
        "<!-- ENG -->\n",
        "##### Exercise 5\n",
        "　<var>K</var>-means clustering requires the number of clusters to be entered in advance. Not only limited to <var>K</var>-means clustering, but there are many cases in clustering where you have to specify how many clusters to divide into.\n",
        "**Discuss and describe a method for objectively determining the number of clusters.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfSZMeN9LtNc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKJxnlz40ZO6"
      },
      "source": [
        "<!-- JPN -->\n",
        "##### 課題 6（実践）\n",
        "　課題 5 で考えたクラスタ数を客観的に決めるための方法をGaussianデータセット、moonデータセット両方に適用し、機能したかどうか、それは何故か、考察せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK92ER7fD_Kp"
      },
      "source": [
        "<!-- ENG -->\n",
        "##### Exercise 6 (Practical)\n",
        "　Apply the method for objectively determining the number of clusters considered in Exercise 5. to both the Gaussian and moon data sets, and discuss whether it worked and why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSZLBIKBLveS"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca2ibReSualg"
      },
      "source": [
        "<!-- JPN -->\n",
        "## 4 | クラスタリングを用いた仮説提案の例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNzXykpUD_Kq"
      },
      "source": [
        "<!-- ENG -->\n",
        "## 4 | Example of a hypothesis formulation using clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ladbJRTxuzSw"
      },
      "source": [
        "<!-- JPN -->\n",
        "　クラスタリングなどの教師なし学習では、答え（〇/×、あるいは予測したい数値）が存在しないことが多々あり、このような場合には**解析結果から新しい仮説を立てることが重要になる**。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKTwuGz6D_Kr"
      },
      "source": [
        "<!-- ENG -->\n",
        "　In unsupervised learning such as clustering, the answer (YES/NO or the number you want to predict) often does not exist, and in such cases **it is important to formulate a new hypothesis from the analysis results**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TM79xiy-nsM"
      },
      "source": [
        "<!-- JPN -->\n",
        "　ここでは、Kaggleに公開されている通販の顧客データセット（おそらく人工データ、1次ソースはUdemyの資料のようだ）に対して<var>K</var>-meansクラスタリングを実施、どのような結果が得られるのかを確かめてみる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELevXrvKD_Kr"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Here, we will perform <var>K</var>-means clustering on the mail order customer data set available on Kaggle (likely artificial data, primary source seems to be Udemy's material) and see what kind of results we get."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt8KxjF-JeCu"
      },
      "source": [
        "https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VqL-l9lJeCu"
      },
      "source": [
        "<!-- JPN -->\n",
        "　この結果から、どういう層に売り込みをかければいいのか、を考えようとしている、と想像してほしい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DatBgzRcJeCu"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Imagine that you are trying to figure out what kind of audience you should market to based on these results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UamGCHts_Gso"
      },
      "source": [
        "<!-- JPN -->\n",
        "　さて、今回は「年収」「購入スコア（購買履歴などから計算されたスコア）」について<var>K</var>-meansクラスタリングを行ってみる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-t_4z6tD_Ks"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Now, let's try <var>K</var>-means clustering for \"annual income\" and \"spending score (score calculated from purchase history, etc.)\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHE3uMFsu1lB"
      },
      "outputs": [],
      "source": [
        "# Preparing a data set\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "# Get data sets from the Internet\n",
        "url = \"https://raw.githubusercontent.com/SteffiPeTaffy/machineLearningAZ/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv\"\n",
        "download = requests.get(url).content\n",
        "csv_string = io.StringIO(download.decode('utf-8'))\n",
        "data_df = pd.read_csv(csv_string)\n",
        "data_df = data_df.drop(\"CustomerID\", axis=1) # Delete Customer ID column\n",
        "data_df = data_df.drop(\"Genre\", axis=1)      # Remove Genre column (gender) as it is too cumbersome to process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZJcn1Xt_vrt"
      },
      "outputs": [],
      "source": [
        "print(data_df.head())\n",
        "print(\"------------\")\n",
        "print(data_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHJk1uM-BNtU"
      },
      "source": [
        "<!-- JPN -->\n",
        "　ここから年収と購買スコアを取得して<var>K</var>-meansクラスタリングを行うのだが、この2種類の値は異なる分散を持つ。**<var>K</var>-meansクラスタリングはデータ間のユークリッド距離を通常用いる**ため、より分散が大きい特徴量が重要であるかのように取り扱われてしまう。\n",
        "\n",
        "　これを避けるためには、**<var>K</var>-meansクラスタリングを行う前に標準化**を行えばよい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mroLkCqpD_Kt"
      },
      "source": [
        "<!-- ENG -->\n",
        "　From here, we get the annual income and spending score to perform <var>K</var>-means clustering, and these two types of values have different variances. Since **<var>K</var>-means clustering usually uses the Euclidean distance between data**, features with higher variance are treated as if they are more important.\n",
        "\n",
        "\n",
        "\n",
        "　To avoid this, you should carry out **standardization before implementing <var>K</var>-means clustering**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzWi5mVHcj1y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = data_df[[\"Annual Income (k$)\", \"Spending Score (1-100)\"]].values\n",
        "X_std = StandardScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAYFCFo9FAbt"
      },
      "source": [
        "<!-- JPN -->\n",
        "　では、<var>K</var>-meansクラスタリングを実施してみよう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mgSnTJQD_Kt"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Now, let's try implementing <var>K</var>-means clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAzo_cQTFDVN"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kmeans_random_seed = 0\n",
        "n_clusters = 5\n",
        "kmeans = KMeans(random_state=kmeans_random_seed, n_clusters=n_clusters)\n",
        "kmeans.fit(X_std)\n",
        "\n",
        "\n",
        "# Figure drawing\n",
        "plt.figure(figsize=(6, 6))\n",
        "cmap = plt.get_cmap('gist_rainbow')\n",
        "for i in range(n_clusters):\n",
        "    plt.scatter(data_df.loc[kmeans.labels_==i, \"Annual Income (k$)\"], \n",
        "                data_df.loc[kmeans.labels_==i, \"Spending Score (1-100)\"],\n",
        "                color=cmap(i/n_clusters))\n",
        "\n",
        "plt.xlabel(\"Annual Income (k$)\")\n",
        "plt.ylabel(\"Spending Score (1-100)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLsvPvV_GuVu"
      },
      "source": [
        "<!-- JPN -->\n",
        "　なるほど、かなり明確に5つのクラスタに分割できるようである。それぞれのグループの各要素の平均値などはどうなっているだろうか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZyDyBpJD_Ku"
      },
      "source": [
        "<!-- ENG -->\n",
        "　Well, it seems that it can be divided into five clusters quite clearly. What is the mean value etc. of each element for each group?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVUn5e4fG78X"
      },
      "outputs": [],
      "source": [
        "for i in range(n_clusters):\n",
        "  print(\"cluster\", i)\n",
        "  print(data_df[kmeans.labels_==i].mean())\n",
        "  print(\"----------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz2JfmRbHfr0"
      },
      "source": [
        "<!-- JPN -->\n",
        "　この結果から、例えば以下のようなことがわかる。\n",
        "\n",
        "- 購買スコアも年収も高い「理想的な顧客」のクラスタの平均年齢が若いことから、それらの顧客を離さない戦略が重要であるかもしれない。\n",
        "- 一方で、年収が高いにも関わらず購買スコアが低い「潜在能力のある顧客」のクラスタの平均年齢は高いため、新規顧客の獲得は中高年層に対して行うべきかもしれない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iKLw2tCD_Kv"
      },
      "source": [
        "<!-- ENG -->\n",
        "　The results show, for example, the following.\n",
        "\n",
        "- Since the average age of the cluster of \"ideal customers\" with high spending scores and annual income is young, strategies to keep those customers engaged may be important.\n",
        "\n",
        "- On the other hand, the average age of the cluster of \"potential customers\" with low spending scores despite their high annual income is high, so perhaps new customer acquisition should be done for middle-aged and older people."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEPkqWtMeV42"
      },
      "source": [
        "<!-- JPN -->\n",
        "　このような解析を行うことで、 **人間が目視して発見するよりも簡単に、かつ高速に、様々な仮説を立てる**ことができるようになる。\n",
        "\n",
        "　ただし、利用する特徴量、あるいはクラスタ数は人間の主観が入る。データ数が少ない時は人間の感覚の介入が顕著になる。**あくまで仮説であり、絶対の事実ではない**ことを意識して、新しい顧客（＝データ）が来たときに、この仮説が成り立っているか、新しい戦略を打った時に想定通りの変化が起きているかどうかを注視することが重要である。\n",
        "\n",
        "　この演習を通して述べることだが、 **「データは愛でるくらい見なければならない」** ことを忘れてはならないのである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4i7rodMD_Kv"
      },
      "source": [
        "<!-- ENG -->\n",
        "　This kind of analysis will allow us to **formulate various hypotheses more easily and faster than a human can discover by sight**.\n",
        "\n",
        "　However, the number of features or clusters to be used is subjective. When the number of data is small, the intervention of human perception becomes more pronounced. It is important to be aware that **this is only a hypothesis and not an absolute fact**, and to keep an eye on whether this hypothesis holds true when new customers (i.e., data) arrive, and whether the changes occur as expected when new strategies are implemented.\n",
        "\n",
        "　As we want to emphasize throughout this practice exercise, it is important to remember that **\"you have to look at the data like you love doing it\"**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JG8boFZ0Spj"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfoHGg_YWyto"
      },
      "source": [
        "<!-- JPN -->\n",
        "## レポートフォーマット\n",
        "\n",
        "提出を行う際には以下のフォーマットを利用せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTuy6MF4_qRU"
      },
      "source": [
        "<!-- ENG -->\n",
        "## Report format\n",
        "\n",
        "Use a format shown below when you submit your report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRy597BTJeC0"
      },
      "source": [
        "https://docs.google.com/document/d/1nNV4-4DnslkCoDXlDSrlMgAO7g4lrCLfKkH6WXPzknE/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxHEDgxJIy6y"
      },
      "source": [
        "<!-- JPN -->\n",
        "# 補足資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSDAoxeiD_Kx"
      },
      "source": [
        "<!-- ENG -->\n",
        "# Supplementary Material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-kz0DP3I-ST"
      },
      "source": [
        "<!-- JPN -->\n",
        "## ※1 | `sklearn.cluster.AgglomerativeClustering()` と `scipy.cluster.hierarchy()` の関係\n",
        "\n",
        "　クラスタリングを行う場合には scikit-learn を、樹形図 (dendrogram) を描画する場合には SciPy を利用した。通常、異なるライブラリを利用すると、ライブラリの実装方法によって結果が多少異なるはずだ。しかし、`sklearn.cluster.AgglomerativeClustering()` は内部で `scipy.cluster.hierarchy()` が使われており、出力作成にあたって構成されるクラスタリングや、クラスタリング手法を選択するキーワード（`ward`や`complete`など）は完全に同一のものになっている。\n",
        "\n",
        "　以上の理由から、2つのライブラリを横断的に利用してクラスタリングと樹形図の描画を行ったが、scikit-learnのホームページを見ると、 `AgglomerativeClustering()` から樹形図を作る方法も示されている。難解なので授業では利用しなかったが、参照すると、 `Z` がどういうデータなのか、それをどのように作成するのかなど、より深い理解につながるかもしれない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2pBjWbID_Kx"
      },
      "source": [
        "<!-- ENG -->\n",
        "## S1 | Relationship between `sklearn.cluster.AgglomerativeClustering() ` and ` scipy.cluster.hierarchy()`\n",
        "\n",
        "　scikit-learn was used for clustering, and SciPy was used for drawing dendrograms. Usually, if you use different libraries, the results should be somewhat different depending on how the library is implemented. However, `sklearn.cluster.AgglomerativeClustering()` uses `scipy.cluster.hierarchy()` internally, and the clustering which is consisted for output creation and keywords for selecting the clustering method (such as `ward` and `complete`) are completely identical.\n",
        "\n",
        "　For these reasons, the two libraries were used across the board for clustering and drawing dendrograms, but the scikit-learn homepage also shows how to create dendrograms from `AgglomerativeClustering()`. This method was not used in the lecture because it is difficult to understand, but referring to it may lead to a deeper understanding of what kind of data `Z` is and how to create it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQB3nQUaJeC1"
      },
      "source": [
        "https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}